{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Data/train_yaOffsB.csv')\n",
    "test_data = pd.read_csv('../Data/test_pFkWwen.csv')\n",
    "sample_submission = pd.read_csv('../Data/sample_submission_O1oDc4H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 'ID'\n",
    "target = 'Crop_Damage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Season', 'Pesticide_Use_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Number_Weeks_Used'] = train_data['Number_Weeks_Used'].fillna(0)\n",
    "test_data['Number_Weeks_Used'] = test_data['Number_Weeks_Used'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    if (column not in categorical_columns) & (column!=ID) & (column!=target):\n",
    "        \n",
    "        mms = MinMaxScaler()\n",
    "        ss = StandardScaler()\n",
    "        rs = RobustScaler()\n",
    "        pt = PowerTransformer()\n",
    "        ft_log = FunctionTransformer(np.log1p)\n",
    "        \n",
    "        train_data[f'{column}_mms'] = mms.fit_transform(train_data[[column]])\n",
    "        test_data[f'{column}_mms'] = mms.transform(test_data[[column]])\n",
    "        \n",
    "        train_data[f'{column}_ss'] = ss.fit_transform(train_data[[column]])\n",
    "        test_data[f'{column}_ss'] = ss.transform(test_data[[column]])\n",
    "        \n",
    "        train_data[f'{column}_rs'] = rs.fit_transform(train_data[[column]])\n",
    "        test_data[f'{column}_rs'] = rs.transform(test_data[[column]])\n",
    "        \n",
    "        train_data[f'{column}_pt'] = pt.fit_transform(train_data[[column]])\n",
    "        test_data[f'{column}_pt'] = pt.transform(test_data[[column]])\n",
    "        \n",
    "        train_data[f'{column}_ft_log'] = ft_log.fit_transform(train_data[[column]])\n",
    "        test_data[f'{column}_ft_log'] = ft_log.transform(test_data[[column]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['is_train'] = True\n",
    "test_data['is_train'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    train_data[column] = train_data[column].apply(lambda x: f'{column}_{x}')\n",
    "    test_data[column] = test_data[column].apply(lambda x: f'{column}_{x}')\n",
    "    \n",
    "for idx, column in enumerate(categorical_columns):\n",
    "    _tmp = pd.concat([train_data[['is_train', column]], test_data[['is_train', column]]])\n",
    "    _tmp_ohe = pd.get_dummies(_tmp[column])\n",
    "\n",
    "    if idx==0:\n",
    "        _tmp_final = pd.concat([_tmp[['is_train']], _tmp_ohe], axis=1)\n",
    "    else:\n",
    "        _tmp_final = pd.concat([_tmp_final, _tmp_ohe], axis=1)\n",
    "\n",
    "train_data = pd.concat([train_data.drop(categorical_columns+['is_train'], axis=1), _tmp_final[_tmp_final['is_train']]], axis=1)\n",
    "test_data = pd.concat([test_data.drop(categorical_columns+['is_train'], axis=1), _tmp_final[~_tmp_final['is_train']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_data.drop(['ID','Crop_Damage','is_train'], axis=1), \n",
    "                                                  train_data[['Crop_Damage']], test_size = 0.3, \n",
    "                                                  random_state = 1234, stratify = train_data['Crop_Damage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_estimators = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF': RandomForestClassifier(n_estimators = no_of_estimators, max_depth=10, random_state=1234),\n",
    "    'GBM_ES': GradientBoostingClassifier(n_estimators = no_of_estimators, max_depth=10, random_state=1234, \n",
    "                                      validation_fraction=0.2, n_iter_no_change=50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DT model starts\n",
      "The average accuracy of DT model on training data is 0.75 with a std of +/- 0.16 %\n",
      "The average ROC score of the DT model on validation data is 0.75\n",
      "Building DT model ends\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Building RF model starts\n",
      "The average accuracy of RF model on training data is 0.84 with a std of +/- 0.17 %\n",
      "The average ROC score of the RF model on validation data is 0.85\n",
      "Building RF model ends\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Building GBM_ES model starts\n",
      "The average accuracy of GBM_ES model on training data is 0.83 with a std of +/- 0.28 %\n",
      "The average ROC score of the GBM_ES model on validation data is 0.84\n",
      "Building GBM_ES model ends\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for clf, model in models.items():\n",
    "    print(f\"Building {clf} model starts\")\n",
    "    cv_scores = cross_val_score(model, X_train, y_train.values.ravel(), cv=5, scoring='accuracy')\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    y_pred = model.predict(X_val)\n",
    "    val_score = accuracy_score(y_val.values.ravel(), y_pred)\n",
    "    print(f\"The average accuracy of {clf} model on training data is {np.round(cv_scores.mean(),2)} with a std of +/- {np.round((cv_scores.std()/cv_scores.mean())*100,2)} %\")\n",
    "    print(f\"The average ROC score of the {clf} model on validation data is {np.round(val_score,2)}\")\n",
    "    print(f\"Building {clf} model ends\")\n",
    "    print(f\"---------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1234,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['RF'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
